{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6WT8hTfenmr"
      },
      "source": [
        "# Trabalho 01 - TT003A\n",
        "## Professor: Ulisses Martins Dias\n",
        "## Integrantes:\n",
        "- Bruno Ricardo Corrêa - 260759\n",
        "- Vinícius Iutaka Nogueira Fujioka - 260933"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPcZUsM8fJGA"
      },
      "source": [
        "Enunciado (remover depois):\n",
        "\n",
        "Neste trabalho, você deve mostrar que consegue utilizar redes neurais em um cenário de aprendizado supervisionado básico. Neste trabalho, você não receberá um notebook como ponto de partida, mas deverá construir um do zero, de preferência usando códigos vistos em sala de aula. Existe um grupo de videoaulas sobre o banco de dados iris e sobre o banco de dados titanic que devem lhe ajudar a resolver este trabalho sem maiores problemas.\n",
        "\n",
        "Neste trabalho, você deverá escolher um banco de dados no kaggle ou em qualquer lugar da internet. Dê preferência para dados já estruturados de forma tabular, evitando o uso de bancos de dados de imagens, por exemplo. Existe vários formatos de dados nesse formato na internet. Feito isso, você deverá selecionar que tipo de problema está tratando: classificação binária, multiclasse, ou regressão para resolver o problema de forma apropriada.\n",
        "\n",
        "Vale lembrar que você deverá separar o seu conjunto de dados em treino e teste para que seja possível, ao final, computar um valor de acurácia.\n",
        "\n",
        "Nesta atividade, você será avaliado da seguinte forma:\n",
        "1.   Consegue apresentar o banco de dados e explicar o cenário.\n",
        "2.   Consegue processar os dados de entrada de modo a ser possível inserir na rede neural as entradas (tratar missing values e converter valores para dados numéricos).\n",
        "3. Consegue criar uma rede neural usando o método de herança de nn.Module.\n",
        "4. Consegue escolher uma função de custo adequada. Se você escolher uma função de custo que não condiz com o problema, então será descontado os seus pontos neste item, mesmo que o treinamento convirja.\n",
        "5. Consegue utilizar um otimizador qualquer da biblioteca PyTorch. Se você errar no uso do otimizador, então será descontado os seus pontos neste item, mesmo que o treinamento convirja.\n",
        "6. Consegue utilizar Mini-Batches.\n",
        "7. Consegue computar uma acurácia com o banco de dados de teste.\n",
        "8. Consegue gerar um modelo em que a acurácia é melhor do que o que seria obtido ao acaso."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lsbv2er9gglo"
      },
      "source": [
        "Atividades:\n",
        "- Escolher database no kaggle ou outro lugar com dados tabulares.\n",
        "    - dataset escolhido: [https://www.kaggle.com/datasets/rashikrahmanpritom/heart-attack-analysis-prediction-dataset](https://www.kaggle.com/datasets/rashikrahmanpritom/heart-attack-analysis-prediction-dataset)\n",
        "    - Dados presentes no dataset:\n",
        "        - age: idade do paciente\n",
        "        - sex: sexo do paciente (1 = masculino; 0 = feminino)\n",
        "        - exang: angina induzida por exercício (1 = sim; 0 = não)\n",
        "        - caa: número de grandes vasos (0-3) coloridos por fluoroscopia\n",
        "        - cp: tipo de dor no peito (1 = angina típica; 2 = angina atípica; 3 = dor não anginal; 0 = assintomática)\n",
        "        - trtbps: pressão sanguínea em repouso em mmHg\n",
        "        - chol: colesterol sérico em mg/dl\n",
        "        - fbs: açúcar no sangue em jejum > 120 mg/dl (1 = verdadeiro; 0 = falso)\n",
        "        - restecg: resultados eletrocardiográficos em repouso (0 = hipertrofia ventricular; 1 = normal; 2 = anormalidade da onda ST-T)\n",
        "        - thalachh: frequência cardíaca máxima alcançada\n",
        "        - oldpeak: depressão do segmento ST induzida pelo exercício em relação ao repouso\n",
        "        - slp: inclinação do segmento ST de pico do exercício (0 = descendente; 1 = plano; 2 = ascendente)\n",
        "        - thall: talassemia (0 = normal; 1 = defeito fixo; 2 = defeito reversível)\n",
        "        - output: 0 = menos chance de ataque cardíaco; 1 = mais chance de ataque cardíaco\n",
        "\n",
        "- Selecionar que tipo de problema está tratando: classificação binária, multiclasse, ou regressão para resolver o problema de forma apropriada.\n",
        "    - classificação binária: prever se um paciente tem uma disposição maior a sofrer um ataque cardíaco ou não.\n",
        "    - Dados utilizados: \n",
        "        - age: idade do paciente\n",
        "        - cp: tipo de dor no peito (1 = angina típica; 2 = angina atípica; 3 = dor não anginal; 0 = assintomática) \n",
        "        - trtbps: pressão sanguínea em repouso em mmHg \n",
        "        - chol: colesterol sérico em mg/dl \n",
        "        - fbs: açúcar no sangue em jejum > 120 mg/dl (1 = verdadeiro e 0 = falso) \n",
        "        - restecg: resultados eletrocardiográficos em repouso (1 = normal; 2 = anormalidade da onda ST-T; 0 = hipertrofia ventricular) \n",
        "        - thalachh: frequência cardíaca máxima alcançada \n",
        "        - exang: angina induzida por exercício (1 = sim e 0 = não) \n",
        "        - oldpeak: depressão do segmento ST induzida pelo exercício em relação ao repouso \n",
        "        - slp: inclinação do segmento ST de pico do exercício (2 = ascendente; 1 = plano; 0 = descendente) \n",
        "        - caa: número de grandes vasos (0-3) coloridos por fluoroscopia \n",
        "        - thall: talassemia (2 = normal; 1 = defeito fixo; 3 = defeito reversível).\n",
        "\n",
        "\n",
        "(Fluoroscopia é o exame que se usa radiação ionizante para verificar o funcionamento em tempo real de órgãos internos do corpo humano, e pode-se adicionar contraste para melhorar a visualização e detectar entupimentos em vasos sanguíneos, no caso do dataset em questão, os vasos sanguíneos do coração.)\n",
        "\n",
        "- Separar o seu conjunto de dados em treino e teste para que seja possível, ao final, computar um valor de acurácia.\n",
        "    - 80% dos dados para treino e 20% para teste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "Sopa0FueeglW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "f58me4Ydi3Kz"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('heart.csv')\n",
        "\n",
        "train = df.sample(frac=0.8, random_state=35)\n",
        "test = df.drop(train.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PCygKfHr7hzL",
        "outputId": "a995f436-7a71-4dbd-d67c-3cdd0f2091ef"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trtbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalachh</th>\n",
              "      <th>exng</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slp</th>\n",
              "      <th>caa</th>\n",
              "      <th>thall</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>242.000000</td>\n",
              "      <td>242.000000</td>\n",
              "      <td>242.000000</td>\n",
              "      <td>242.000000</td>\n",
              "      <td>242.00000</td>\n",
              "      <td>242.00000</td>\n",
              "      <td>242.000000</td>\n",
              "      <td>242.000000</td>\n",
              "      <td>242.000000</td>\n",
              "      <td>242.000000</td>\n",
              "      <td>242.000000</td>\n",
              "      <td>242.000000</td>\n",
              "      <td>242.000000</td>\n",
              "      <td>242.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>54.243802</td>\n",
              "      <td>0.669421</td>\n",
              "      <td>0.954545</td>\n",
              "      <td>131.545455</td>\n",
              "      <td>245.50000</td>\n",
              "      <td>0.14876</td>\n",
              "      <td>0.533058</td>\n",
              "      <td>149.508264</td>\n",
              "      <td>0.342975</td>\n",
              "      <td>0.999587</td>\n",
              "      <td>1.400826</td>\n",
              "      <td>0.698347</td>\n",
              "      <td>2.301653</td>\n",
              "      <td>0.566116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>9.167554</td>\n",
              "      <td>0.471396</td>\n",
              "      <td>1.027627</td>\n",
              "      <td>18.363323</td>\n",
              "      <td>47.62764</td>\n",
              "      <td>0.35659</td>\n",
              "      <td>0.524248</td>\n",
              "      <td>22.985697</td>\n",
              "      <td>0.475687</td>\n",
              "      <td>1.166386</td>\n",
              "      <td>0.624931</td>\n",
              "      <td>1.040626</td>\n",
              "      <td>0.621133</td>\n",
              "      <td>0.496637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>29.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>131.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>47.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>211.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>133.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>55.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>239.50000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>153.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>61.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>273.75000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>165.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>77.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>417.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>202.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.200000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              age         sex          cp      trtbps       chol        fbs  \\\n",
              "count  242.000000  242.000000  242.000000  242.000000  242.00000  242.00000   \n",
              "mean    54.243802    0.669421    0.954545  131.545455  245.50000    0.14876   \n",
              "std      9.167554    0.471396    1.027627   18.363323   47.62764    0.35659   \n",
              "min     29.000000    0.000000    0.000000   94.000000  131.00000    0.00000   \n",
              "25%     47.250000    0.000000    0.000000  120.000000  211.00000    0.00000   \n",
              "50%     55.000000    1.000000    1.000000  130.000000  239.50000    0.00000   \n",
              "75%     61.000000    1.000000    2.000000  140.000000  273.75000    0.00000   \n",
              "max     77.000000    1.000000    3.000000  200.000000  417.00000    1.00000   \n",
              "\n",
              "          restecg    thalachh        exng     oldpeak         slp         caa  \\\n",
              "count  242.000000  242.000000  242.000000  242.000000  242.000000  242.000000   \n",
              "mean     0.533058  149.508264    0.342975    0.999587    1.400826    0.698347   \n",
              "std      0.524248   22.985697    0.475687    1.166386    0.624931    1.040626   \n",
              "min      0.000000   71.000000    0.000000    0.000000    0.000000    0.000000   \n",
              "25%      0.000000  133.000000    0.000000    0.000000    1.000000    0.000000   \n",
              "50%      1.000000  153.000000    0.000000    0.600000    1.000000    0.000000   \n",
              "75%      1.000000  165.000000    1.000000    1.600000    2.000000    1.000000   \n",
              "max      2.000000  202.000000    1.000000    6.200000    2.000000    4.000000   \n",
              "\n",
              "            thall      output  \n",
              "count  242.000000  242.000000  \n",
              "mean     2.301653    0.566116  \n",
              "std      0.621133    0.496637  \n",
              "min      0.000000    0.000000  \n",
              "25%      2.000000    0.000000  \n",
              "50%      2.000000    1.000000  \n",
              "75%      3.000000    1.000000  \n",
              "max      3.000000    1.000000  "
            ]
          },
          "execution_count": 164,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.describe(include='all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
              "       1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
              "       0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "       0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n",
              "       0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0,\n",
              "       0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
              "       1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0])"
            ]
          },
          "execution_count": 165,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train = train.loc[:, ['age', 'cp', 'trtbps', 'chol', 'fbs', 'restecg', 'thalachh', 'exng', 'oldpeak', 'slp', 'caa', 'thall']]\n",
        "x_test = test.loc[:, ['age', 'cp', 'trtbps', 'chol', 'fbs', 'restecg', 'thalachh', 'exng', 'oldpeak', 'slp', 'caa', 'thall']]\n",
        "        \n",
        "y_train = train.output.values\n",
        "y_test = test.output.values\n",
        "\n",
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train = torch.tensor(x_train.values, dtype=torch.float)\n",
        "x_test = torch.tensor(x_test.values, dtype=torch.float)\n",
        "\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {},
      "outputs": [],
      "source": [
        "maximo = x_train.max(dim=0).values\n",
        "minimo = x_train.min(dim=0).values\n",
        "\n",
        "x_train = (x_train - minimo) / (maximo - minimo)\n",
        "x_test = (x_test - minimo) / (maximo - minimo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[0.5833, 0.3333, 0.3396,  ..., 0.5000, 0.2500, 0.6667],\n",
              "         [0.6458, 0.0000, 0.2170,  ..., 1.0000, 0.5000, 1.0000],\n",
              "         [0.5208, 0.0000, 0.1509,  ..., 0.5000, 0.2500, 1.0000],\n",
              "         ...,\n",
              "         [0.5417, 0.0000, 0.4340,  ..., 0.0000, 0.0000, 1.0000],\n",
              "         [0.3542, 0.0000, 0.4151,  ..., 0.5000, 0.0000, 0.6667],\n",
              "         [0.3958, 0.0000, 0.2830,  ..., 0.5000, 0.0000, 1.0000]]),\n",
              " tensor([0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "         1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "         1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0,\n",
              "         0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0,\n",
              "         1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0,\n",
              "         1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
              "         0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n",
              "         1, 0]))"
            ]
          },
          "execution_count": 168,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train, y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[ 0.2500,  0.3333,  0.3396,  0.2552,  0.0000,  0.0000,  0.7710,  0.0000,\n",
              "           0.2258,  1.0000,  0.0000,  0.6667],\n",
              "         [ 0.5833,  0.6667,  0.5283,  0.1294,  0.0000,  0.5000,  0.7863,  0.0000,\n",
              "           0.2581,  1.0000,  0.0000,  0.6667],\n",
              "         [ 0.2917,  0.0000,  0.5283,  0.4056,  0.0000,  0.5000,  0.7634,  0.0000,\n",
              "           0.2419,  1.0000,  0.0000,  0.6667],\n",
              "         [ 0.8333,  1.0000,  0.4340,  0.3776,  0.0000,  0.5000,  0.6107,  0.0000,\n",
              "           0.2903,  1.0000,  0.5000,  0.6667],\n",
              "         [ 0.5000,  0.6667,  0.3396,  0.2308,  1.0000,  0.0000,  0.6183,  0.0000,\n",
              "           0.1935,  0.0000,  0.0000,  0.6667],\n",
              "         [ 0.5208,  0.6667,  0.2925,  0.4965,  0.0000,  0.0000,  0.6183,  0.0000,\n",
              "           0.0806,  0.0000,  0.2500,  0.6667],\n",
              "         [ 0.4792,  0.3333,  0.2453,  0.6783,  0.0000,  0.5000,  0.7710,  0.0000,\n",
              "           0.0323,  1.0000,  0.0000,  0.6667],\n",
              "         [ 0.4792,  0.3333,  0.3774,  0.2448,  0.0000,  0.5000,  0.6641,  0.0000,\n",
              "           0.1290,  1.0000,  0.2500,  0.6667],\n",
              "         [ 0.3333,  0.0000,  0.1981,  0.4510,  0.0000,  0.0000,  0.8702,  0.0000,\n",
              "           0.0000,  1.0000,  0.0000,  0.6667],\n",
              "         [ 0.5833,  0.0000,  0.3208,  0.6014,  0.0000,  0.0000,  0.6718,  0.0000,\n",
              "           0.0000,  1.0000,  0.2500,  0.6667],\n",
              "         [ 0.4583,  0.6667,  0.2925,  0.3986,  1.0000,  0.0000,  0.7252,  0.0000,\n",
              "           0.3871,  0.5000,  0.0000,  0.6667],\n",
              "         [ 0.6458,  0.6667,  0.0755,  0.6538,  0.0000,  0.5000,  0.6794,  0.0000,\n",
              "           0.0000,  1.0000,  0.2500,  0.6667],\n",
              "         [ 0.7917,  0.6667,  0.1981,  1.5140,  0.0000,  0.0000,  0.6794,  0.0000,\n",
              "           0.2581,  0.5000,  0.0000,  1.0000],\n",
              "         [ 0.5208,  0.3333,  0.3585,  0.5490,  1.0000,  0.0000,  0.6718,  1.0000,\n",
              "           0.0000,  1.0000,  0.2500,  0.6667],\n",
              "         [ 0.2708,  1.0000,  0.5094,  0.3951,  0.0000,  0.0000,  0.8168,  0.0000,\n",
              "           0.1290,  1.0000,  0.5000,  0.6667],\n",
              "         [ 0.5833,  0.6667,  0.5283, -0.0175,  1.0000,  0.5000,  0.7786,  0.0000,\n",
              "           0.0323,  1.0000,  0.2500,  1.0000],\n",
              "         [ 0.4167,  0.3333,  0.3774,  0.4895,  0.0000,  0.5000,  0.6947,  0.0000,\n",
              "           0.0000,  0.5000,  0.0000,  0.6667],\n",
              "         [ 0.2500,  0.3333,  0.3019,  0.6119,  0.0000,  0.5000,  0.7023,  0.0000,\n",
              "           0.0000,  1.0000,  0.0000,  0.6667],\n",
              "         [ 0.7292,  0.0000,  0.3208,  0.4615,  0.0000,  0.5000,  0.2595,  1.0000,\n",
              "           0.0323,  0.5000,  0.2500,  1.0000],\n",
              "         [ 0.9792,  0.6667,  0.4340,  0.2308,  0.0000,  1.0000,  0.3435,  0.0000,\n",
              "           0.1774,  0.5000,  0.0000,  0.6667],\n",
              "         [ 0.6458,  1.0000,  0.5283,  0.3811,  0.0000,  0.5000,  0.7634,  0.0000,\n",
              "           0.1452,  1.0000,  0.0000,  0.6667],\n",
              "         [ 0.3125,  0.6667,  0.2453,  0.3322,  0.0000,  0.5000,  0.7481,  0.0000,\n",
              "           0.0000,  1.0000,  0.0000,  0.6667],\n",
              "         [ 0.2708,  0.6667,  0.3396,  0.1713,  0.0000,  0.5000,  0.6031,  0.0000,\n",
              "           0.0000,  1.0000,  0.0000,  0.6667],\n",
              "         [ 0.8750,  0.0000,  0.1698,  0.0629,  0.0000,  0.5000,  0.4122,  0.0000,\n",
              "           0.2581,  0.5000,  0.0000,  0.6667],\n",
              "         [ 0.2083,  0.6667,  0.4151,  0.3112,  0.0000,  0.5000,  0.6183,  0.0000,\n",
              "           0.0000,  0.5000,  0.0000,  0.6667],\n",
              "         [ 0.3750,  0.6667,  0.3396,  0.4266,  0.0000,  0.5000,  0.8244,  0.0000,\n",
              "           0.0000,  1.0000,  0.0000,  0.6667],\n",
              "         [ 0.5625,  0.3333,  0.2453,  0.3811,  0.0000,  0.5000,  0.7481,  0.0000,\n",
              "           0.0000,  0.0000,  0.0000,  0.6667],\n",
              "         [ 0.2500,  0.3333,  0.2453,  0.0909,  0.0000,  0.5000,  0.8473,  0.0000,\n",
              "           0.0000,  1.0000,  0.0000,  0.6667],\n",
              "         [ 0.5625,  0.6667,  0.3396,  0.4371,  1.0000,  0.0000,  0.5420,  1.0000,\n",
              "           0.0968,  0.5000,  0.2500,  0.3333],\n",
              "         [ 0.6042,  0.3333,  0.2453,  0.5350,  0.0000,  0.0000,  0.6794,  0.0000,\n",
              "           0.2903,  0.5000,  0.0000,  0.6667],\n",
              "         [ 0.6042,  0.6667,  0.3585,  0.3252,  0.0000,  0.0000,  0.7786,  0.0000,\n",
              "           0.5161,  1.0000,  0.5000,  1.0000],\n",
              "         [ 0.6042,  0.6667,  0.1698,  0.3462,  0.0000,  0.0000,  0.7176,  0.0000,\n",
              "           0.4032,  0.5000,  0.2500,  1.0000],\n",
              "         [ 0.4375,  0.0000,  0.5283,  0.3916,  0.0000,  0.0000,  0.4351,  0.0000,\n",
              "           0.4194,  0.5000,  0.0000,  1.0000],\n",
              "         [ 0.2500,  0.0000,  0.1509,  0.1434,  0.0000,  0.0000,  0.6641,  0.0000,\n",
              "           0.0000,  1.0000,  0.0000,  1.0000],\n",
              "         [ 0.4583,  0.0000,  0.3396,  0.6084,  0.0000,  0.5000,  0.5420,  1.0000,\n",
              "           0.1935,  0.5000,  0.0000,  1.0000],\n",
              "         [ 0.5208,  0.0000,  0.2453,  0.1993,  0.0000,  0.5000,  0.3206,  0.0000,\n",
              "           0.2258,  0.5000,  0.2500,  1.0000],\n",
              "         [ 0.3542,  0.6667,  0.5283,  0.3497,  0.0000,  0.5000,  0.5802,  0.0000,\n",
              "           0.5806,  0.5000,  0.0000,  0.6667],\n",
              "         [ 0.3125,  0.0000,  0.1509,  0.2308,  0.0000,  0.0000,  0.8092,  0.0000,\n",
              "           0.0000,  1.0000,  0.2500,  0.6667],\n",
              "         [ 0.6458,  0.0000,  0.2925,  0.4441,  0.0000,  0.0000,  0.5344,  1.0000,\n",
              "           0.4516,  0.5000,  0.2500,  1.0000],\n",
              "         [ 0.6042,  0.0000,  0.5283,  0.4860,  0.0000,  0.0000,  0.3053,  1.0000,\n",
              "           0.1290,  1.0000,  0.0000,  1.0000],\n",
              "         [ 0.6875,  0.6667,  0.3396,  0.4615,  0.0000,  0.5000,  0.1985,  0.0000,\n",
              "           0.1935,  0.5000,  0.2500,  1.0000],\n",
              "         [ 0.7500,  1.0000,  0.4151,  0.5280,  1.0000,  0.0000,  0.7863,  0.0000,\n",
              "           0.2258,  0.5000,  0.2500,  0.6667],\n",
              "         [ 0.5417,  0.0000,  0.6226,  0.5524,  0.0000,  0.0000,  0.5649,  1.0000,\n",
              "           0.1290,  0.5000,  0.2500,  1.0000],\n",
              "         [ 0.4583,  0.0000,  0.4340,  0.5874,  0.0000,  0.5000,  0.7786,  1.0000,\n",
              "           0.2581,  1.0000,  0.0000,  1.0000],\n",
              "         [ 0.6042,  0.0000,  0.2925,  0.5909,  0.0000,  0.0000,  0.7634,  0.0000,\n",
              "           0.0000,  1.0000,  0.5000,  1.0000],\n",
              "         [ 0.7292,  0.0000,  0.4811,  0.2832,  0.0000,  0.0000,  0.4656,  0.0000,\n",
              "           0.3226,  0.5000,  0.5000,  0.3333],\n",
              "         [ 0.5625,  0.0000,  0.3774,  0.9720,  0.0000,  0.0000,  0.6031,  1.0000,\n",
              "           0.3065,  0.5000,  0.5000,  1.0000],\n",
              "         [ 0.8333,  0.6667,  0.4340,  0.4301,  0.0000,  0.0000,  0.5725,  0.0000,\n",
              "           0.3226,  0.5000,  0.7500,  1.0000],\n",
              "         [ 0.4583,  0.0000,  0.4340,  0.5839,  0.0000,  0.5000,  0.3893,  1.0000,\n",
              "           0.6774,  0.5000,  0.7500,  1.0000],\n",
              "         [ 0.6875,  0.0000,  0.4151,  0.5699,  1.0000,  0.5000,  0.2672,  0.0000,\n",
              "           0.3065,  0.5000,  0.7500,  0.6667],\n",
              "         [ 0.3333,  0.0000,  0.4528,  0.6224,  0.0000,  0.0000,  0.5802,  1.0000,\n",
              "           0.0000,  0.5000,  0.7500,  1.0000],\n",
              "         [ 0.4375,  0.0000,  0.4717,  0.2413,  0.0000,  0.0000,  0.4198,  1.0000,\n",
              "           0.1452,  0.5000,  0.0000,  1.0000],\n",
              "         [ 0.7708,  0.0000,  0.1698,  0.2832,  0.0000,  0.0000,  0.4656,  1.0000,\n",
              "           0.0161,  1.0000,  0.2500,  0.6667],\n",
              "         [ 0.6667,  1.0000,  0.3774,  0.3601,  0.0000,  0.5000,  0.5649,  0.0000,\n",
              "           0.4194,  0.5000,  0.5000,  0.6667],\n",
              "         [ 0.3750,  0.0000,  0.1509,  0.5035,  0.0000,  0.0000,  0.3588,  1.0000,\n",
              "           0.1613,  0.5000,  0.2500,  0.6667],\n",
              "         [ 0.4792,  0.0000,  0.2925,  0.2832,  0.0000,  0.5000,  0.7405,  0.0000,\n",
              "           0.1613,  1.0000,  0.5000,  1.0000],\n",
              "         [ 0.5833,  0.0000,  0.1509,  0.7133,  0.0000,  0.5000,  0.5496,  1.0000,\n",
              "           0.4839,  0.5000,  0.2500,  1.0000],\n",
              "         [ 0.7917,  0.6667,  0.5472,  0.2832,  0.0000,  0.0000,  0.6031,  0.0000,\n",
              "           0.1290,  0.5000,  0.0000,  1.0000],\n",
              "         [ 0.7083,  0.0000,  0.4340,  0.1958,  0.0000,  0.0000,  0.5573,  1.0000,\n",
              "           0.6452,  1.0000,  0.5000,  1.0000],\n",
              "         [ 0.6250,  0.0000,  0.6604,  0.1573,  1.0000,  0.0000,  0.1450,  0.0000,\n",
              "           0.1613,  0.5000,  0.5000,  0.3333],\n",
              "         [ 0.8125,  0.0000,  0.4717,  0.2168,  1.0000,  0.5000,  0.5344,  0.0000,\n",
              "           0.5484,  0.5000,  0.5000,  1.0000]]),\n",
              " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
            ]
          },
          "execution_count": 169,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_test, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ArtificialNeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(12, 16)\n",
        "        self.fc2 = nn.Linear(16, 16)\n",
        "        self.fc3 = nn.Linear(16, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.sigmoid(self.fc1(x))\n",
        "        x = torch.sigmoid(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "model = ArtificialNeuralNetwork()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/1000], Loss: 0.6267\n",
            "Epoch [101/1000], Loss: 0.2984\n",
            "Epoch [201/1000], Loss: 0.2387\n",
            "Epoch [301/1000], Loss: 0.2301\n",
            "Epoch [401/1000], Loss: 0.2278\n",
            "Epoch [501/1000], Loss: 0.2272\n",
            "Epoch [601/1000], Loss: 0.2268\n",
            "Epoch [701/1000], Loss: 0.2260\n",
            "Epoch [801/1000], Loss: 0.2244\n",
            "Epoch [901/1000], Loss: 0.2216\n",
            "Final Loss value: 0.2970\n"
          ]
        }
      ],
      "source": [
        "learning_rate = 0.001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "num_epochs = 1000\n",
        "batch_size = 32\n",
        "train_data = torch.utils.data.TensorDataset(x_train, y_train)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs).squeeze()\n",
        "\n",
        "        loss = loss_fn(outputs, labels.float())\n",
        "\n",
        "        if (epoch % (num_epochs / 10) == 0 and i == 0):\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "print(f\"Final Loss value: {loss.item():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0.,\n",
              "        1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "        0., 0., 0., 1., 0., 0., 0.], grad_fn=<RoundBackward0>)"
            ]
          },
          "execution_count": 172,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = model(x_test).squeeze()\n",
        "y_pred = torch.round(torch.sigmoid(y_pred))\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ANN Accuracy in %: 85.25\n"
          ]
        }
      ],
      "source": [
        "accuracy_ann = (y_pred == y_test).sum()/len(y_test)\n",
        "print(f\"ANN Accuracy in %: {accuracy_ann.item()*100:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 598,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Accuracy in %: 46.86\n"
          ]
        }
      ],
      "source": [
        "num_instances = len(df)\n",
        "\n",
        "random_predictions = [random.randint(0, 1) for _ in range(num_instances)]\n",
        "\n",
        "correct_predictions = sum(random_predictions[i] == df['output'][i] for i in range(num_instances))\n",
        "accuracy_random = correct_predictions / num_instances\n",
        "\n",
        "print(f\"Random Accuracy in %: {accuracy_random*100:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_names = ['Artificial Neural Network', 'Random']\n",
        "accuracies = [accuracy_ann.item(), accuracy_random]\n",
        "\n",
        "data = pd.DataFrame({'Model': model_names, 'Accuracy': accuracies})\n",
        "\n",
        "ax = sns.barplot(x='Model', y='Accuracy', data=data, hue='Model', palette='viridis', legend=False)\n",
        "\n",
        "ax.set_xlabel('Model')\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.set_title('Comparison of Model Accuracies')\n",
        "\n",
        "ax.set_ylim(0, 1)\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
