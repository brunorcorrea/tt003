{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6WT8hTfenmr"
      },
      "source": [
        "# Trabalho 01 - TT003A\n",
        "## Professor: Ulisses Martins Dias\n",
        "## Integrantes:\n",
        "- Bruno Ricardo Corrêa - 260759\n",
        "- Vinícius Iutaka Nogueira Fujioka - 260933"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPcZUsM8fJGA"
      },
      "source": [
        "Enunciado (remover depois):\n",
        "\n",
        "Neste trabalho, você deve mostrar que consegue utilizar redes neurais em um cenário de aprendizado supervisionado básico. Neste trabalho, você não receberá um notebook como ponto de partida, mas deverá construir um do zero, de preferência usando códigos vistos em sala de aula. Existe um grupo de videoaulas sobre o banco de dados iris e sobre o banco de dados titanic que devem lhe ajudar a resolver este trabalho sem maiores problemas.\n",
        "\n",
        "Neste trabalho, você deverá escolher um banco de dados no kaggle ou em qualquer lugar da internet. Dê preferência para dados já estruturados de forma tabular, evitando o uso de bancos de dados de imagens, por exemplo. Existe vários formatos de dados nesse formato na internet. Feito isso, você deverá selecionar que tipo de problema está tratando: classificação binária, multiclasse, ou regressão para resolver o problema de forma apropriada.\n",
        "\n",
        "Vale lembrar que você deverá separar o seu conjunto de dados em treino e teste para que seja possível, ao final, computar um valor de acurácia.\n",
        "\n",
        "Nesta atividade, você será avaliado da seguinte forma:\n",
        "1.   Consegue apresentar o banco de dados e explicar o cenário.\n",
        "2.   Consegue processar os dados de entrada de modo a ser possível inserir na rede neural as entradas (tratar missing values e converter valores para dados numéricos).\n",
        "3. Consegue criar uma rede neural usando o método de herança de nn.Module.\n",
        "4. Consegue escolher uma função de custo adequada. Se você escolher uma função de custo que não condiz com o problema, então será descontado os seus pontos neste item, mesmo que o treinamento convirja.\n",
        "5. Consegue utilizar um otimizador qualquer da biblioteca PyTorch. Se você errar no uso do otimizador, então será descontado os seus pontos neste item, mesmo que o treinamento convirja.\n",
        "6. Consegue utilizar Mini-Batches.\n",
        "7. Consegue computar uma acurácia com o banco de dados de teste.\n",
        "8. Consegue gerar um modelo em que a acurácia é melhor do que o que seria obtido ao acaso."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lsbv2er9gglo"
      },
      "source": [
        "Atividades:\n",
        "- Escolher database no kaggle ou outro lugar com dados tabulares.\n",
        "    - dataset escolhido: [https://www.kaggle.com/datasets/rashikrahmanpritom/heart-attack-analysis-prediction-dataset](https://www.kaggle.com/datasets/rashikrahmanpritom/heart-attack-analysis-prediction-dataset)\n",
        "    - Dados presentes no dataset:\n",
        "        - age: idade do paciente\n",
        "        - sex: sexo do paciente (1 = masculino; 0 = feminino)\n",
        "        - exang: angina induzida por exercício (1 = sim; 0 = não)\n",
        "        - caa: número de grandes vasos (0-3) coloridos por fluoroscopia\n",
        "        - cp: tipo de dor no peito (1 = angina típica; 2 = angina atípica; 3 = dor não anginal; 0 = assintomática)\n",
        "        - trtbps: pressão sanguínea em repouso em mmHg\n",
        "        - chol: colesterol sérico em mg/dl\n",
        "        - fbs: açúcar no sangue em jejum > 120 mg/dl (1 = verdadeiro; 0 = falso)\n",
        "        - restecg: resultados eletrocardiográficos em repouso (0 = hipertrofia ventricular; 1 = normal; 2 = anormalidade da onda ST-T)\n",
        "        - thalachh: frequência cardíaca máxima alcançada\n",
        "        - oldpeak: depressão do segmento ST induzida pelo exercício em relação ao repouso\n",
        "        - slp: inclinação do segmento ST de pico do exercício (0 = descendente; 1 = plano; 2 = ascendente)\n",
        "        - thall: talassemia (0 = normal; 1 = defeito fixo; 2 = defeito reversível)\n",
        "        - output: 0 = menos chance de ataque cardíaco; 1 = mais chance de ataque cardíaco\n",
        "\n",
        "- Selecionar que tipo de problema está tratando: classificação binária, multiclasse, ou regressão para resolver o problema de forma apropriada.\n",
        "    - classificação binária: prever se um paciente tem uma disposição maior a sofrer um ataque cardíaco ou não.\n",
        "    - Dados utilizados: \n",
        "        - age: idade do paciente\n",
        "        - cp: tipo de dor no peito (1 = angina típica; 2 = angina atípica; 3 = dor não anginal; 0 = assintomática) \n",
        "        - trtbps: pressão sanguínea em repouso em mmHg \n",
        "        - chol: colesterol sérico em mg/dl \n",
        "        - fbs: açúcar no sangue em jejum > 120 mg/dl (1 = verdadeiro e 0 = falso) \n",
        "        - restecg: resultados eletrocardiográficos em repouso (1 = normal; 2 = anormalidade da onda ST-T; 0 = hipertrofia ventricular) \n",
        "        - thalachh: frequência cardíaca máxima alcançada \n",
        "        - exang: angina induzida por exercício (1 = sim e 0 = não) \n",
        "        - oldpeak: depressão do segmento ST induzida pelo exercício em relação ao repouso \n",
        "        - slp: inclinação do segmento ST de pico do exercício (2 = ascendente; 1 = plano; 0 = descendente) \n",
        "        - caa: número de grandes vasos (0-3) coloridos por fluoroscopia \n",
        "        - thall: talassemia (2 = normal; 1 = defeito fixo; 3 = defeito reversível).\n",
        "\n",
        "\n",
        "(Fluoroscopia é o exame que se usa radiação ionizante para verificar o funcionamento em tempo real de órgãos internos do corpo humano, e pode-se adicionar contraste para melhorar a visualização e detectar entupimentos em vasos sanguíneos, no caso do dataset em questão, os vasos sanguíneos do coração.)\n",
        "\n",
        "- Separar o seu conjunto de dados em treino e teste para que seja possível, ao final, computar um valor de acurácia.\n",
        "    - 80% dos dados para treino e 20% para teste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Sopa0FueeglW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "f58me4Ydi3Kz"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('heart.csv')\n",
        "\n",
        "train = df.sample(frac=0.8, random_state=35)\n",
        "test = df.drop(train.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PCygKfHr7hzL",
        "outputId": "a995f436-7a71-4dbd-d67c-3cdd0f2091ef"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trtbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalachh</th>\n",
              "      <th>exng</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slp</th>\n",
              "      <th>caa</th>\n",
              "      <th>thall</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>242.000000</td>\n",
              "      <td>242.000000</td>\n",
              "      <td>242.000000</td>\n",
              "      <td>242.000000</td>\n",
              "      <td>242.00000</td>\n",
              "      <td>242.00000</td>\n",
              "      <td>242.000000</td>\n",
              "      <td>242.000000</td>\n",
              "      <td>242.000000</td>\n",
              "      <td>242.000000</td>\n",
              "      <td>242.000000</td>\n",
              "      <td>242.000000</td>\n",
              "      <td>242.000000</td>\n",
              "      <td>242.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>54.243802</td>\n",
              "      <td>0.669421</td>\n",
              "      <td>0.954545</td>\n",
              "      <td>131.545455</td>\n",
              "      <td>245.50000</td>\n",
              "      <td>0.14876</td>\n",
              "      <td>0.533058</td>\n",
              "      <td>149.508264</td>\n",
              "      <td>0.342975</td>\n",
              "      <td>0.999587</td>\n",
              "      <td>1.400826</td>\n",
              "      <td>0.698347</td>\n",
              "      <td>2.301653</td>\n",
              "      <td>0.566116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>9.167554</td>\n",
              "      <td>0.471396</td>\n",
              "      <td>1.027627</td>\n",
              "      <td>18.363323</td>\n",
              "      <td>47.62764</td>\n",
              "      <td>0.35659</td>\n",
              "      <td>0.524248</td>\n",
              "      <td>22.985697</td>\n",
              "      <td>0.475687</td>\n",
              "      <td>1.166386</td>\n",
              "      <td>0.624931</td>\n",
              "      <td>1.040626</td>\n",
              "      <td>0.621133</td>\n",
              "      <td>0.496637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>29.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>131.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>47.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>211.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>133.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>55.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>239.50000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>153.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>61.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>273.75000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>165.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>77.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>417.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>202.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.200000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              age         sex          cp      trtbps       chol        fbs  \\\n",
              "count  242.000000  242.000000  242.000000  242.000000  242.00000  242.00000   \n",
              "mean    54.243802    0.669421    0.954545  131.545455  245.50000    0.14876   \n",
              "std      9.167554    0.471396    1.027627   18.363323   47.62764    0.35659   \n",
              "min     29.000000    0.000000    0.000000   94.000000  131.00000    0.00000   \n",
              "25%     47.250000    0.000000    0.000000  120.000000  211.00000    0.00000   \n",
              "50%     55.000000    1.000000    1.000000  130.000000  239.50000    0.00000   \n",
              "75%     61.000000    1.000000    2.000000  140.000000  273.75000    0.00000   \n",
              "max     77.000000    1.000000    3.000000  200.000000  417.00000    1.00000   \n",
              "\n",
              "          restecg    thalachh        exng     oldpeak         slp         caa  \\\n",
              "count  242.000000  242.000000  242.000000  242.000000  242.000000  242.000000   \n",
              "mean     0.533058  149.508264    0.342975    0.999587    1.400826    0.698347   \n",
              "std      0.524248   22.985697    0.475687    1.166386    0.624931    1.040626   \n",
              "min      0.000000   71.000000    0.000000    0.000000    0.000000    0.000000   \n",
              "25%      0.000000  133.000000    0.000000    0.000000    1.000000    0.000000   \n",
              "50%      1.000000  153.000000    0.000000    0.600000    1.000000    0.000000   \n",
              "75%      1.000000  165.000000    1.000000    1.600000    2.000000    1.000000   \n",
              "max      2.000000  202.000000    1.000000    6.200000    2.000000    4.000000   \n",
              "\n",
              "            thall      output  \n",
              "count  242.000000  242.000000  \n",
              "mean     2.301653    0.566116  \n",
              "std      0.621133    0.496637  \n",
              "min      0.000000    0.000000  \n",
              "25%      2.000000    0.000000  \n",
              "50%      2.000000    1.000000  \n",
              "75%      3.000000    1.000000  \n",
              "max      3.000000    1.000000  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.describe(include='all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
              "       1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
              "       0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "       0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n",
              "       0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0,\n",
              "       0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
              "       1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train = train.loc[:, ['age', 'cp', 'trtbps', 'chol', 'fbs', 'restecg', 'thalachh', 'exng', 'oldpeak', 'slp', 'caa', 'thall']]\n",
        "x_test = test.loc[:, ['age', 'cp', 'trtbps', 'chol', 'fbs', 'restecg', 'thalachh', 'exng', 'oldpeak', 'slp', 'caa', 'thall']]\n",
        "        \n",
        "y_train = train.output.values\n",
        "y_test = test.output.values\n",
        "\n",
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train = torch.tensor(x_train.values, dtype=torch.float)\n",
        "x_test = torch.tensor(x_test.values, dtype=torch.float)\n",
        "\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "maximo = x_train.max(dim=0).values\n",
        "minimo = x_train.min(dim=0).values\n",
        "\n",
        "x_train = (x_train - minimo) / (maximo - minimo)\n",
        "x_test = (x_test - minimo) / (maximo - minimo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[0.5833, 0.3333, 0.3396,  ..., 0.5000, 0.2500, 0.6667],\n",
              "         [0.6458, 0.0000, 0.2170,  ..., 1.0000, 0.5000, 1.0000],\n",
              "         [0.5208, 0.0000, 0.1509,  ..., 0.5000, 0.2500, 1.0000],\n",
              "         ...,\n",
              "         [0.5417, 0.0000, 0.4340,  ..., 0.0000, 0.0000, 1.0000],\n",
              "         [0.3542, 0.0000, 0.4151,  ..., 0.5000, 0.0000, 0.6667],\n",
              "         [0.3958, 0.0000, 0.2830,  ..., 0.5000, 0.0000, 1.0000]]),\n",
              " tensor([0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "         1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "         1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
              "         0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
              "         1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0,\n",
              "         0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0,\n",
              "         1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0,\n",
              "         1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
              "         0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n",
              "         1, 0]))"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train, y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[ 0.2500,  0.3333,  0.3396,  0.2552,  0.0000,  0.0000,  0.7710,  0.0000,\n",
              "           0.2258,  1.0000,  0.0000,  0.6667],\n",
              "         [ 0.5833,  0.6667,  0.5283,  0.1294,  0.0000,  0.5000,  0.7863,  0.0000,\n",
              "           0.2581,  1.0000,  0.0000,  0.6667],\n",
              "         [ 0.2917,  0.0000,  0.5283,  0.4056,  0.0000,  0.5000,  0.7634,  0.0000,\n",
              "           0.2419,  1.0000,  0.0000,  0.6667],\n",
              "         [ 0.8333,  1.0000,  0.4340,  0.3776,  0.0000,  0.5000,  0.6107,  0.0000,\n",
              "           0.2903,  1.0000,  0.5000,  0.6667],\n",
              "         [ 0.5000,  0.6667,  0.3396,  0.2308,  1.0000,  0.0000,  0.6183,  0.0000,\n",
              "           0.1935,  0.0000,  0.0000,  0.6667],\n",
              "         [ 0.5208,  0.6667,  0.2925,  0.4965,  0.0000,  0.0000,  0.6183,  0.0000,\n",
              "           0.0806,  0.0000,  0.2500,  0.6667],\n",
              "         [ 0.4792,  0.3333,  0.2453,  0.6783,  0.0000,  0.5000,  0.7710,  0.0000,\n",
              "           0.0323,  1.0000,  0.0000,  0.6667],\n",
              "         [ 0.4792,  0.3333,  0.3774,  0.2448,  0.0000,  0.5000,  0.6641,  0.0000,\n",
              "           0.1290,  1.0000,  0.2500,  0.6667],\n",
              "         [ 0.3333,  0.0000,  0.1981,  0.4510,  0.0000,  0.0000,  0.8702,  0.0000,\n",
              "           0.0000,  1.0000,  0.0000,  0.6667],\n",
              "         [ 0.5833,  0.0000,  0.3208,  0.6014,  0.0000,  0.0000,  0.6718,  0.0000,\n",
              "           0.0000,  1.0000,  0.2500,  0.6667],\n",
              "         [ 0.4583,  0.6667,  0.2925,  0.3986,  1.0000,  0.0000,  0.7252,  0.0000,\n",
              "           0.3871,  0.5000,  0.0000,  0.6667],\n",
              "         [ 0.6458,  0.6667,  0.0755,  0.6538,  0.0000,  0.5000,  0.6794,  0.0000,\n",
              "           0.0000,  1.0000,  0.2500,  0.6667],\n",
              "         [ 0.7917,  0.6667,  0.1981,  1.5140,  0.0000,  0.0000,  0.6794,  0.0000,\n",
              "           0.2581,  0.5000,  0.0000,  1.0000],\n",
              "         [ 0.5208,  0.3333,  0.3585,  0.5490,  1.0000,  0.0000,  0.6718,  1.0000,\n",
              "           0.0000,  1.0000,  0.2500,  0.6667],\n",
              "         [ 0.2708,  1.0000,  0.5094,  0.3951,  0.0000,  0.0000,  0.8168,  0.0000,\n",
              "           0.1290,  1.0000,  0.5000,  0.6667],\n",
              "         [ 0.5833,  0.6667,  0.5283, -0.0175,  1.0000,  0.5000,  0.7786,  0.0000,\n",
              "           0.0323,  1.0000,  0.2500,  1.0000],\n",
              "         [ 0.4167,  0.3333,  0.3774,  0.4895,  0.0000,  0.5000,  0.6947,  0.0000,\n",
              "           0.0000,  0.5000,  0.0000,  0.6667],\n",
              "         [ 0.2500,  0.3333,  0.3019,  0.6119,  0.0000,  0.5000,  0.7023,  0.0000,\n",
              "           0.0000,  1.0000,  0.0000,  0.6667],\n",
              "         [ 0.7292,  0.0000,  0.3208,  0.4615,  0.0000,  0.5000,  0.2595,  1.0000,\n",
              "           0.0323,  0.5000,  0.2500,  1.0000],\n",
              "         [ 0.9792,  0.6667,  0.4340,  0.2308,  0.0000,  1.0000,  0.3435,  0.0000,\n",
              "           0.1774,  0.5000,  0.0000,  0.6667],\n",
              "         [ 0.6458,  1.0000,  0.5283,  0.3811,  0.0000,  0.5000,  0.7634,  0.0000,\n",
              "           0.1452,  1.0000,  0.0000,  0.6667],\n",
              "         [ 0.3125,  0.6667,  0.2453,  0.3322,  0.0000,  0.5000,  0.7481,  0.0000,\n",
              "           0.0000,  1.0000,  0.0000,  0.6667],\n",
              "         [ 0.2708,  0.6667,  0.3396,  0.1713,  0.0000,  0.5000,  0.6031,  0.0000,\n",
              "           0.0000,  1.0000,  0.0000,  0.6667],\n",
              "         [ 0.8750,  0.0000,  0.1698,  0.0629,  0.0000,  0.5000,  0.4122,  0.0000,\n",
              "           0.2581,  0.5000,  0.0000,  0.6667],\n",
              "         [ 0.2083,  0.6667,  0.4151,  0.3112,  0.0000,  0.5000,  0.6183,  0.0000,\n",
              "           0.0000,  0.5000,  0.0000,  0.6667],\n",
              "         [ 0.3750,  0.6667,  0.3396,  0.4266,  0.0000,  0.5000,  0.8244,  0.0000,\n",
              "           0.0000,  1.0000,  0.0000,  0.6667],\n",
              "         [ 0.5625,  0.3333,  0.2453,  0.3811,  0.0000,  0.5000,  0.7481,  0.0000,\n",
              "           0.0000,  0.0000,  0.0000,  0.6667],\n",
              "         [ 0.2500,  0.3333,  0.2453,  0.0909,  0.0000,  0.5000,  0.8473,  0.0000,\n",
              "           0.0000,  1.0000,  0.0000,  0.6667],\n",
              "         [ 0.5625,  0.6667,  0.3396,  0.4371,  1.0000,  0.0000,  0.5420,  1.0000,\n",
              "           0.0968,  0.5000,  0.2500,  0.3333],\n",
              "         [ 0.6042,  0.3333,  0.2453,  0.5350,  0.0000,  0.0000,  0.6794,  0.0000,\n",
              "           0.2903,  0.5000,  0.0000,  0.6667],\n",
              "         [ 0.6042,  0.6667,  0.3585,  0.3252,  0.0000,  0.0000,  0.7786,  0.0000,\n",
              "           0.5161,  1.0000,  0.5000,  1.0000],\n",
              "         [ 0.6042,  0.6667,  0.1698,  0.3462,  0.0000,  0.0000,  0.7176,  0.0000,\n",
              "           0.4032,  0.5000,  0.2500,  1.0000],\n",
              "         [ 0.4375,  0.0000,  0.5283,  0.3916,  0.0000,  0.0000,  0.4351,  0.0000,\n",
              "           0.4194,  0.5000,  0.0000,  1.0000],\n",
              "         [ 0.2500,  0.0000,  0.1509,  0.1434,  0.0000,  0.0000,  0.6641,  0.0000,\n",
              "           0.0000,  1.0000,  0.0000,  1.0000],\n",
              "         [ 0.4583,  0.0000,  0.3396,  0.6084,  0.0000,  0.5000,  0.5420,  1.0000,\n",
              "           0.1935,  0.5000,  0.0000,  1.0000],\n",
              "         [ 0.5208,  0.0000,  0.2453,  0.1993,  0.0000,  0.5000,  0.3206,  0.0000,\n",
              "           0.2258,  0.5000,  0.2500,  1.0000],\n",
              "         [ 0.3542,  0.6667,  0.5283,  0.3497,  0.0000,  0.5000,  0.5802,  0.0000,\n",
              "           0.5806,  0.5000,  0.0000,  0.6667],\n",
              "         [ 0.3125,  0.0000,  0.1509,  0.2308,  0.0000,  0.0000,  0.8092,  0.0000,\n",
              "           0.0000,  1.0000,  0.2500,  0.6667],\n",
              "         [ 0.6458,  0.0000,  0.2925,  0.4441,  0.0000,  0.0000,  0.5344,  1.0000,\n",
              "           0.4516,  0.5000,  0.2500,  1.0000],\n",
              "         [ 0.6042,  0.0000,  0.5283,  0.4860,  0.0000,  0.0000,  0.3053,  1.0000,\n",
              "           0.1290,  1.0000,  0.0000,  1.0000],\n",
              "         [ 0.6875,  0.6667,  0.3396,  0.4615,  0.0000,  0.5000,  0.1985,  0.0000,\n",
              "           0.1935,  0.5000,  0.2500,  1.0000],\n",
              "         [ 0.7500,  1.0000,  0.4151,  0.5280,  1.0000,  0.0000,  0.7863,  0.0000,\n",
              "           0.2258,  0.5000,  0.2500,  0.6667],\n",
              "         [ 0.5417,  0.0000,  0.6226,  0.5524,  0.0000,  0.0000,  0.5649,  1.0000,\n",
              "           0.1290,  0.5000,  0.2500,  1.0000],\n",
              "         [ 0.4583,  0.0000,  0.4340,  0.5874,  0.0000,  0.5000,  0.7786,  1.0000,\n",
              "           0.2581,  1.0000,  0.0000,  1.0000],\n",
              "         [ 0.6042,  0.0000,  0.2925,  0.5909,  0.0000,  0.0000,  0.7634,  0.0000,\n",
              "           0.0000,  1.0000,  0.5000,  1.0000],\n",
              "         [ 0.7292,  0.0000,  0.4811,  0.2832,  0.0000,  0.0000,  0.4656,  0.0000,\n",
              "           0.3226,  0.5000,  0.5000,  0.3333],\n",
              "         [ 0.5625,  0.0000,  0.3774,  0.9720,  0.0000,  0.0000,  0.6031,  1.0000,\n",
              "           0.3065,  0.5000,  0.5000,  1.0000],\n",
              "         [ 0.8333,  0.6667,  0.4340,  0.4301,  0.0000,  0.0000,  0.5725,  0.0000,\n",
              "           0.3226,  0.5000,  0.7500,  1.0000],\n",
              "         [ 0.4583,  0.0000,  0.4340,  0.5839,  0.0000,  0.5000,  0.3893,  1.0000,\n",
              "           0.6774,  0.5000,  0.7500,  1.0000],\n",
              "         [ 0.6875,  0.0000,  0.4151,  0.5699,  1.0000,  0.5000,  0.2672,  0.0000,\n",
              "           0.3065,  0.5000,  0.7500,  0.6667],\n",
              "         [ 0.3333,  0.0000,  0.4528,  0.6224,  0.0000,  0.0000,  0.5802,  1.0000,\n",
              "           0.0000,  0.5000,  0.7500,  1.0000],\n",
              "         [ 0.4375,  0.0000,  0.4717,  0.2413,  0.0000,  0.0000,  0.4198,  1.0000,\n",
              "           0.1452,  0.5000,  0.0000,  1.0000],\n",
              "         [ 0.7708,  0.0000,  0.1698,  0.2832,  0.0000,  0.0000,  0.4656,  1.0000,\n",
              "           0.0161,  1.0000,  0.2500,  0.6667],\n",
              "         [ 0.6667,  1.0000,  0.3774,  0.3601,  0.0000,  0.5000,  0.5649,  0.0000,\n",
              "           0.4194,  0.5000,  0.5000,  0.6667],\n",
              "         [ 0.3750,  0.0000,  0.1509,  0.5035,  0.0000,  0.0000,  0.3588,  1.0000,\n",
              "           0.1613,  0.5000,  0.2500,  0.6667],\n",
              "         [ 0.4792,  0.0000,  0.2925,  0.2832,  0.0000,  0.5000,  0.7405,  0.0000,\n",
              "           0.1613,  1.0000,  0.5000,  1.0000],\n",
              "         [ 0.5833,  0.0000,  0.1509,  0.7133,  0.0000,  0.5000,  0.5496,  1.0000,\n",
              "           0.4839,  0.5000,  0.2500,  1.0000],\n",
              "         [ 0.7917,  0.6667,  0.5472,  0.2832,  0.0000,  0.0000,  0.6031,  0.0000,\n",
              "           0.1290,  0.5000,  0.0000,  1.0000],\n",
              "         [ 0.7083,  0.0000,  0.4340,  0.1958,  0.0000,  0.0000,  0.5573,  1.0000,\n",
              "           0.6452,  1.0000,  0.5000,  1.0000],\n",
              "         [ 0.6250,  0.0000,  0.6604,  0.1573,  1.0000,  0.0000,  0.1450,  0.0000,\n",
              "           0.1613,  0.5000,  0.5000,  0.3333],\n",
              "         [ 0.8125,  0.0000,  0.4717,  0.2168,  1.0000,  0.5000,  0.5344,  0.0000,\n",
              "           0.5484,  0.5000,  0.5000,  1.0000]]),\n",
              " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_test, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ArtificialNeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(12, 16)\n",
        "        self.fc2 = nn.Linear(16, 16)\n",
        "        self.fc3 = nn.Linear(16, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.sigmoid(self.fc1(x))\n",
        "        x = torch.sigmoid(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "model = ArtificialNeuralNetwork()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/1000], Loss: 0.6476\n",
            "Epoch [101/1000], Loss: 0.2942\n",
            "Epoch [201/1000], Loss: 0.2351\n",
            "Epoch [301/1000], Loss: 0.2267\n",
            "Epoch [401/1000], Loss: 0.2248\n",
            "Epoch [501/1000], Loss: 0.2249\n",
            "Epoch [601/1000], Loss: 0.2258\n",
            "Epoch [701/1000], Loss: 0.2268\n",
            "Epoch [801/1000], Loss: 0.2276\n",
            "Epoch [901/1000], Loss: 0.2278\n",
            "Final Loss value: 0.3296\n"
          ]
        }
      ],
      "source": [
        "learning_rate = 0.001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "num_epochs = 1000\n",
        "batch_size = 32\n",
        "train_data = torch.utils.data.TensorDataset(x_train, y_train)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs).squeeze()\n",
        "\n",
        "        loss = loss_fn(outputs, labels.float())\n",
        "\n",
        "        if (epoch % (num_epochs / 10) == 0 and i == 0):\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "print(f\"Final Loss value: {loss.item():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0.,\n",
              "        1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "        0., 0., 0., 1., 0., 0., 0.], grad_fn=<RoundBackward0>)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = model(x_test).squeeze()\n",
        "y_pred = torch.round(torch.sigmoid(y_pred))\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ANN Accuracy in %: 85.25\n"
          ]
        }
      ],
      "source": [
        "accuracy_ann = (y_pred == y_test).sum()/len(y_test)\n",
        "print(f\"ANN Accuracy in %: {accuracy_ann.item()*100:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Accuracy in %: 51.49\n"
          ]
        }
      ],
      "source": [
        "num_instances = len(df)\n",
        "\n",
        "random_predictions = [random.randint(0, 1) for _ in range(num_instances)]\n",
        "\n",
        "correct_predictions = sum(random_predictions[i] == df['output'][i] for i in range(num_instances))\n",
        "accuracy_random = correct_predictions / num_instances\n",
        "\n",
        "print(f\"Random Accuracy in %: {accuracy_random*100:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_names = ['Artificial Neural Network', 'Random']\n",
        "accuracies = [accuracy_ann.item(), accuracy_random]\n",
        "\n",
        "data = pd.DataFrame({'Model': model_names, 'Accuracy': accuracies})\n",
        "\n",
        "ax = sns.barplot(x='Model', y='Accuracy', data=data, hue='Model', palette='viridis', legend=False)\n",
        "\n",
        "ax.set_xlabel('Model')\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.set_title('Comparison of Model Accuracies')\n",
        "\n",
        "ax.set_ylim(0, 1)\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
